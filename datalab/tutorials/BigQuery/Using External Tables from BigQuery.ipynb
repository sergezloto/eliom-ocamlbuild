{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using External Tables from BigQuery\n",
    "\n",
    "BigQuery has the ability to query data directly from Google Cloud Storage (a feature called Federated Data Sources). This can be useful when querying small amounts of data that you may not want to load into a BigQuery table. It is not recommended for large queries, because BigQuery billing is based on the amount of data read to process a query. BigQuery can very efficiently query subsets of tables in its own store as these are stored in columnar format, so the unused columns are not read and don't add any cost. Data stored in GCS is typically going to be in a possibly compressed CSV file and the entire file will need to be read. So this is a useful feature but should be used judiciously. \n",
    "\n",
    "In this notebook we will show you how to download some data from a source on the Internet, put it in GCS, and then query it directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the Data and Loading into GCS\n",
    "\n",
    "For this sample we want to use some external data in a CSV, load it into GCS and query it. The data we will use is the Seattle bike station data from the [Pronto 2015 Data Challenge dataset](https://www.prontocycleshare.com/datachallenge).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gcp\n",
    "import gcp.bigquery as bq\n",
    "import gcp.storage as gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 4230 bytes\n"
     ]
    }
   ],
   "source": [
    "import urllib2\n",
    "\n",
    "data_source = \"https://storage.googleapis.com/cloud-datalab-samples/udfsample/2015_station_data.csv\"\n",
    "\n",
    "f = urllib2.urlopen(data_source)\n",
    "data = f.read()\n",
    "f.close()\n",
    "\n",
    "print 'Read %d bytes' % len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get a bucket in the current project\n",
    "project = gcp.Context.default().project_id\n",
    "sample_bucket_name = project + '-station_data'\n",
    "\n",
    "# Create and write to the GCS item\n",
    "sample_bucket = gs.Bucket(sample_bucket_name)\n",
    "sample_bucket.create()\n",
    "sample_item = sample_bucket.item('station_data.csv')\n",
    "sample_item.write_to(data, 'text/plain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a FederatedTable Object\n",
    "\n",
    "Now we need to create a special FederatedTable object that refers to the data, and that can in turn be used as a table in our BigQuery queries. We need to provide a schema for BigQuery to be able to use the data. The CSV file has a header row that we want to skip; we will use the `CSVOptions` for this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "options = bq.CSVOptions(skip_leading_rows=1)  # Skip the header row\n",
    "\n",
    "schema = bq.Schema([\n",
    "  {'name': 'id', 'type': 'INTEGER'},         # row ID\n",
    "  {'name': 'name', 'type': 'STRING'},        # friendly name\n",
    "  {'name': 'terminal', 'type': 'STRING'},    # terminal ID\n",
    "  {'name': 'lat', 'type': 'FLOAT'},          # latitude\n",
    "  {'name': 'long', 'type': 'FLOAT'},         # longitude\n",
    "  {'name': 'dockcount', 'type': 'INTEGER'},  # bike capacity\n",
    "  {'name': 'online', 'type': 'STRING'}       # date station opened\n",
    "])\n",
    "\n",
    "drivedata = bq.FederatedTable.from_storage(sample_item.uri, # The gs:// URL of the file\n",
    "                                           csv_options=options,\n",
    "                                           schema=schema,\n",
    "                                           max_bad_records=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying the Table\n",
    "\n",
    "Now let's verify that we can access the data. We will run a simple query to show the first 5 rows. Note how we specify the federated table by using just a name in the query, and then passing the table in using a data_sources dictionary parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bqtv\" id=\"1_144832446836\"><table><tr><th>id</th><th>name</th><th>terminal</th><th>lat</th><th>long</th><th>dockcount</th><th>online</th></tr><tr><td>1</td><td>3rd Ave &amp; Broad St</td><td>BT-01</td><td>47.6184196472</td><td>-122.350967407</td><td>18</td><td>10/13/2014</td></tr><tr><td>2</td><td>2nd Ave &amp; Vine St</td><td>BT-03</td><td>47.6158294678</td><td>-122.348564148</td><td>16</td><td>10/13/2014</td></tr><tr><td>3</td><td>6th Ave &amp; Blanchard St</td><td>BT-04</td><td>47.6160926819</td><td>-122.3411026</td><td>16</td><td>10/13/2014</td></tr><tr><td>4</td><td>2nd Ave &amp; Blanchard St</td><td>BT-05</td><td>47.6131095886</td><td>-122.344207764</td><td>14</td><td>10/13/2014</td></tr><tr><td>5</td><td>2nd Ave &amp; Pine St</td><td>CBD-13</td><td>47.6101837158</td><td>-122.339637756</td><td>18</td><td>10/13/2014</td></tr></table></div>\n",
       "    <br />(rows: 5, time: 2.5s,     4KB processed, job: job_OEVY5_7j_NZ0_5y2VTP48ulHVYU)<br />\n",
       "    <script>\n",
       "      require(['extensions/charting', 'element!1_144832446836', 'style!/static/extensions/charting.css'],\n",
       "        function(charts, dom) {\n",
       "          charts.render(dom,\n",
       "            {\n",
       "              chartStyle:\"table\",\n",
       "              dataName:\"0\",\n",
       "              fields:\"id,name,terminal,lat,long,dockcount,online\",\n",
       "              totalRows:5,\n",
       "              rowsPerPage:25,\n",
       "            }, {}, {\"rows\": [{\"c\": [{\"v\": 1}, {\"v\": \"3rd Ave & Broad St\"}, {\"v\": \"BT-01\"}, {\"v\": 47.6184196472168}, {\"v\": -122.35096740722656}, {\"v\": 18}, {\"v\": \"10/13/2014\"}]}, {\"c\": [{\"v\": 2}, {\"v\": \"2nd Ave & Vine St\"}, {\"v\": \"BT-03\"}, {\"v\": 47.61582946777344}, {\"v\": -122.34856414794922}, {\"v\": 16}, {\"v\": \"10/13/2014\"}]}, {\"c\": [{\"v\": 3}, {\"v\": \"6th Ave & Blanchard St\"}, {\"v\": \"BT-04\"}, {\"v\": 47.616092681884766}, {\"v\": -122.34110260009766}, {\"v\": 16}, {\"v\": \"10/13/2014\"}]}, {\"c\": [{\"v\": 4}, {\"v\": \"2nd Ave & Blanchard St\"}, {\"v\": \"BT-05\"}, {\"v\": 47.61310958862305}, {\"v\": -122.34420776367188}, {\"v\": 14}, {\"v\": \"10/13/2014\"}]}, {\"c\": [{\"v\": 5}, {\"v\": \"2nd Ave & Pine St\"}, {\"v\": \"CBD-13\"}, {\"v\": 47.61018371582031}, {\"v\": -122.33963775634766}, {\"v\": 18}, {\"v\": \"10/13/2014\"}]}], \"cols\": [{\"type\": \"number\", \"id\": \"id\", \"label\": \"id\"}, {\"type\": \"string\", \"id\": \"name\", \"label\": \"name\"}, {\"type\": \"string\", \"id\": \"terminal\", \"label\": \"terminal\"}, {\"type\": \"number\", \"id\": \"lat\", \"label\": \"lat\"}, {\"type\": \"number\", \"id\": \"long\", \"label\": \"long\"}, {\"type\": \"number\", \"id\": \"dockcount\", \"label\": \"dockcount\"}, {\"type\": \"string\", \"id\": \"online\", \"label\": \"online\"}]});\n",
       "        }\n",
       "      );\n",
       "    </script>\n",
       "  "
      ],
      "text/plain": [
       "QueryResultsTable job_OEVY5_7j_NZ0_5y2VTP48ulHVYU"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bq.Query('SELECT * FROM data LIMIT 5', data_sources={'data': drivedata}).results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's clean up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_item.delete()\n",
    "sample_bucket.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
