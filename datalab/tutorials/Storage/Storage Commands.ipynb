{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storage Commands\n",
    "\n",
    "Cloud Datalab provides a set of commands for working with data stored in Google Cloud Storage. This is especially interesting for working against data files containing data that is not in BigQuery, or to use it for managing data imported into or exported from BigQuery.\n",
    "\n",
    "This notebook introduces various Storage commands that Cloud Datalab introduces into the notebook environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Commands\n",
    "\n",
    "The commands cover the ability to list storage buckets, and the contained objects, manage them, as well as read from and write to those objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: storage [-h] {copy,create,delete,list,read,view,write} ...\n",
      "\n",
      "Execute various storage-related operations. Use \"%storage <command> -h\" for\n",
      "help on a specific command.\n",
      "\n",
      "positional arguments:\n",
      "  {copy,create,delete,list,read,view,write}\n",
      "                        commands\n",
      "    copy                Copy one or more GCS objects to a different location.\n",
      "    create              Create one or more GCS buckets.\n",
      "    delete              Delete one or more GCS buckets or objects.\n",
      "    list                List buckets in a project, or contents of a bucket.\n",
      "    read                Read the contents of a storage object into a Python\n",
      "                        variable.\n",
      "    view                View the contents of a storage object.\n",
      "    write               Write the value of a Python variable to a storage\n",
      "                        object.\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n"
     ]
    }
   ],
   "source": [
    "%%storage --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Buckets and Objects\n",
    "\n",
    "Items or files held in Cloud Storage are called objects. These are immutable once written. They are organized into buckets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First a couple of commands to list the Cloud Datalab sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>Bucket</th><th>Created</th></tr><tr><td>gs://cloud-datalab-samples</td><td>2015-10-04 16:47:48.785000+00:00</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%storage list --project cloud-datalab-samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>Name</th><th>Type</th><th>Size</th><th>Updated</th></tr><tr><td>applogs</td><td>application/octet-stream</td><td>506050</td><td>2015-11-24 00:06:07.588000+00:00</td></tr><tr><td>carprices/testing.csv</td><td>text/csv</td><td>3635</td><td>2015-10-06 09:02:03.638000+00:00</td></tr><tr><td>carprices/training.csv</td><td>text/csv</td><td>15018</td><td>2015-10-06 09:01:46.040000+00:00</td></tr><tr><td>cars.csv</td><td>text/csv</td><td>248</td><td>2015-10-05 04:58:10.481000+00:00</td></tr><tr><td>cars2.csv</td><td>text/csv</td><td>92</td><td>2015-10-05 05:41:30.935000+00:00</td></tr><tr><td>hello.txt</td><td>text/plain</td><td>14</td><td>2015-10-05 04:48:39.433000+00:00</td></tr><tr><td>httplogs/logs20140615.csv</td><td>text/csv</td><td>23799981</td><td>2015-10-06 08:39:42.605000+00:00</td></tr><tr><td>httplogs/logs20140616.csv</td><td>text/csv</td><td>86323745</td><td>2015-10-06 08:39:43.067000+00:00</td></tr><tr><td>httplogs/logs20140617.csv</td><td>text/csv</td><td>51282558</td><td>2015-10-06 08:39:43.622000+00:00</td></tr><tr><td>httplogs/logs20140618.csv</td><td>text/csv</td><td>53380318</td><td>2015-10-06 08:39:44.191000+00:00</td></tr><tr><td>httplogs/logs20140619.csv</td><td>text/csv</td><td>87691363</td><td>2015-10-06 08:39:44.794000+00:00</td></tr><tr><td>httplogs/logs20140620.csv</td><td>text/csv</td><td>47229334</td><td>2015-10-06 08:39:45.236000+00:00</td></tr><tr><td>httplogs/logs_sample.csv</td><td>text/csv</td><td>3949</td><td>2015-10-06 08:39:45.729000+00:00</td></tr><tr><td>udfsample/</td><td>application/x-www-form-urlencoded;charset=UTF-8</td><td>0</td><td>2015-11-23 23:57:38.494000+00:00</td></tr><tr><td>udfsample/2015_station_data.csv</td><td>text/csv</td><td>4230</td><td>2015-11-24 00:20:14.575000+00:00</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%storage list --bucket gs://cloud-datalab-samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try this command to list any buckets within the current project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%storage list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket: gs://cloud-ml-users-datalab-samples\n",
      "Object: gs://cloud-ml-users-datalab-samples/Hello.txt\n"
     ]
    }
   ],
   "source": [
    "# Some code to determine a unique bucket name for the purposes of the sample\n",
    "import gcp\n",
    "\n",
    "project = gcp.Context.default().project_id\n",
    "sample_bucket_name = project + '-datalab-samples'\n",
    "sample_bucket_path = 'gs://' + sample_bucket_name\n",
    "sample_bucket_object = sample_bucket_path + '/Hello.txt'\n",
    "\n",
    "print 'Bucket: ' + sample_bucket_path\n",
    "print 'Object: ' + sample_bucket_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: In the examples below, the variables will be referenced in the command using `$` syntax, since the names are determined based on the current project. In your scenarios, you might be able to use literal values if they are constant, rather than creating and using variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%storage create --bucket $sample_bucket_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%storage list --bucket $sample_bucket_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%storage copy --source gs://cloud-datalab-samples/hello.txt --destination $sample_bucket_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>Name</th><th>Type</th><th>Size</th><th>Updated</th></tr><tr><td>Hello.txt</td><td>text/plain</td><td>14</td><td>2016-01-30 00:04:12.218000+00:00</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%storage list --bucket $sample_bucket_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello World!\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%storage view --object $sample_bucket_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%storage read --object $sample_bucket_object --variable text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = 'Hello World!\\n====\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%storage write --variable text --object $sample_bucket_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>Name</th><th>Type</th><th>Size</th><th>Updated</th></tr><tr><td>Hello.txt</td><td>text/plain</td><td>18</td><td>2016-01-30 00:04:14.100000+00:00</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%storage list --bucket $sample_bucket_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%storage delete --object $sample_bucket_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%storage delete --bucket $sample_bucket_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking Ahead\n",
    "\n",
    "The Storage commands seen above build on the Storage APIs included in Cloud Datalab. The next notebook will demonstrate these APIs.\n",
    "\n",
    "Additionally, the BigQuery functionality supports exporting data to and importing data from Cloud Storage, as shown in the BigQuery tutorials."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
